{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim, autograd as grad\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code classifies 10 different classes of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.convL1 = nn.Conv2d(in_channels=3,out_channels=128, \n",
    "                                kernel_size=(3,3), stride= (1,1),padding=2)\n",
    "        nn.init.kaiming_normal(self.convL1.weight)\n",
    "        self.convL2 = nn.Conv2d(in_channels=128,out_channels=64, \n",
    "                                kernel_size=(3,3), stride= (1,1),padding=2)\n",
    "        nn.init.kaiming_normal(self.convL2.weight)\n",
    "        self.convL3 = nn.Conv2d(in_channels=64,out_channels=32, \n",
    "                                kernel_size=(2,2), stride= (1,1),padding=2)\n",
    "        nn.init.kaiming_normal(self.convL1.weight)\n",
    "\n",
    "\n",
    "        self.linL4 = nn.Linear(2592, 1000, bias=True)\n",
    "        self.linL5 = nn.Linear(1000, 10, bias=True)\n",
    "        nn.init.kaiming_uniform_(self.linL4.weight)\n",
    "        nn.init.kaiming_uniform_(self.linL5.weight)\n",
    "        self.pool3 = nn.MaxPool2d((3,3), (3,3))\n",
    "        self.pool2 = nn.MaxPool2d((2,2), (2,2))\n",
    "\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.relu = nn.ReLU()  \n",
    "        self.Batch_norm = nn.BatchNorm1d(num_features=32)\n",
    "        self.Lrelu = nn.LeakyReLU()\n",
    "        self.Softplus = nn.Softplus()\n",
    "        self.Softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.Batch_norm(x)\n",
    "        x=self.Lrelu(self.convL1(x))\n",
    "        x=self.pool3(x)\n",
    "        x=self.relu(self.convL2(x))\n",
    "        x=self.pool2(x)\n",
    "        x=self.relu(self.convL3(x))\n",
    "\n",
    "        x=torch.flatten(x)\n",
    "        x=self.Lrelu(self.linL4(x))\n",
    "        x=self.dropout(x)\n",
    "        x=self.Softmax(self.linL5(x))\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.data[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_shape(training_set)->str:\n",
    "    ret_string = \"\"\n",
    "    for idx, data in enumerate(training_set):\n",
    "            datas = data[0]\n",
    "            labels = data[1]\n",
    "            ret_string+=\"{}\\n\".format(datas.shape)\n",
    "            ret_string+=\"Labels:{}\\n\".format(labels)\n",
    "            ret_string+=\"Labels shape:{}\\n\".format(len(labels))\n",
    "            ret_string+=\"Labels[0] shape:{}\\n\".format(labels[0].shape)\n",
    "            break\n",
    "    return ret_string\n",
    "\n",
    "\n",
    "def max_index(max_tnsr):\n",
    "    max_tnsr = torch.tensor(max_tnsr)\n",
    "    max_tnsr = max_tnsr.tolist()\n",
    "    max_num = 0\n",
    "    for num in max_tnsr:\n",
    "        if max_num < num:\n",
    "            max_num = num\n",
    "    return max_tnsr.index(max_num)\n",
    "\n",
    "\n",
    "def val_func(convNet, cnn_num,valDS): # Selects the best network\n",
    "                                                #   out of n networks\n",
    "    cnns_loss = [0]*cnn_num # represents the 10 cnns\n",
    "    print(\"\\n| Starting validation set run |\\n\")\n",
    "    for val_sample in valDS:\n",
    "        for j in range(cnn_num):\n",
    "            prediction = convNet[j].forward(torch.squeeze(val_sample[0]))\n",
    "            loss_func = nn.CrossEntropyLoss()\n",
    "            loss = loss_func(prediction, val_sample[1])\n",
    "            cnns_loss[j]+=loss # Adds the loss of the\n",
    "    cnns_loss = [j*-1 for j in cnns_loss]\n",
    "    return convNet[max_index(cnns_loss)]# picks the cnn with the lowest loss\n",
    "\n",
    "\n",
    "def train_one_epoch(Cnn, FILE_PATH, train_ds, optimizer):\n",
    "    iter = 0\n",
    "\n",
    "    for sample in train_ds:\n",
    "        targetY = torch.nn.functional.one_hot(\n",
    "        torch.tensor(sample[1]), num_classes=10)\n",
    "        targetY = torch.tensor(targetY, dtype=torch.float32, requires_grad=True)\n",
    "        targetY = torch.squeeze(targetY)\n",
    "            \n",
    "        #optimizer = optim.Adam(params=Cnn.parameters(), weight_decay=0.1\n",
    "        #                      , lr=1e-4, betas=[0.09, 0.0999])\n",
    "        \n",
    "        pred = Cnn.forward(torch.squeeze(sample[0]))\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        # ---BackPropagation---\n",
    "        loss = loss_func(pred, targetY)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if iter%100==0:\n",
    "            torch.save(Cnn.cpu(), FILE_PATH)\n",
    "            grad_tmp = Cnn.linL5.weight.grad\n",
    "            print(iter,\" | \",grad_tmp.sum()/len(grad_tmp))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        iter+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = \"model.pth\"\n",
    "plot_lst = []\n",
    "cnn_num = 10\n",
    "\n",
    "\n",
    "def train_net(cnn, train_ds, pretrain_ds, val_ds, dev):\n",
    "    lrs = [num / int(1e4) for num in range(1, 11)]# The learning rates of\n",
    "                                                #the 10 different CNNs\n",
    "    momentums = [num/10 + 0.09 for num in range(0,10)]\n",
    "    momentums = momentums[4:] + momentums[:4]# Shift from the middle\n",
    "    \n",
    "    #optimizer = optim.Adam(params=cnn.parameters(), weight_decay=0.01\n",
    "    #                    , lr=1e-4, betas=[0.6, 0.6])\n",
    "    \n",
    "\n",
    "    # Multiple pretraining part with a minibatch (10,000)\n",
    "    for i in range(len(cnn)):\n",
    "        optimizer = optim.SGD(params=cnn[i].parameters(), lr=lrs[i],\n",
    "                            momentum=momentums[i], weight_decay=0.0001)\n",
    "        train_one_epoch(cnn[i], FILE_PATH, train_ds=pretrain_ds, optimizer=optimizer)\n",
    "\n",
    "    optimizer = optim.SGD(params=cnn.parameters(), lr=8e-4,\n",
    "                            momentum=0.699,\n",
    "                            weight_decay=0.0001)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # Accessing processing unit\n",
    "    net = [0]*cnn_num\n",
    "    if torch.cuda.is_available() : device = \"cuda:0\"\n",
    "    else : device = \"cpu\"\n",
    "    device = torch.device(device)\n",
    "    for i in range(cnn_num):\n",
    "        net[i]=CNN().to(device)\n",
    "\n",
    "    # Loading the dataset\n",
    "\n",
    "    train_data = torchvision.datasets.CIFAR10(\n",
    "        root= \"C:/Users/orian/OneDrive/שולחן העבודה/My Coding Files\"\n",
    "        ,train=True, transform=transforms.Compose([transforms.ToTensor()\n",
    "                        #,transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                        ])\n",
    "        #, target_transform=transforms.Compose([transforms.ToTensor()])\n",
    "    )\n",
    "\n",
    "    val_split = 500\n",
    "    pretrain_ds, tmp = random_split(train_data, \n",
    "                [val_split, len(train_data)-val_split])\n",
    "    pretrain_ds = DataLoader(pretrain_ds, shuffle=True)\n",
    "    train_data = DataLoader(train_data, shuffle=True)\n",
    "\n",
    "    test_ds = torchvision.datasets.CIFAR10(\n",
    "            root= \"C:/Users/orian/OneDrive/שולחן העבודה/My Coding Files\"\n",
    "            ,train=False, transform=transforms.Compose([transforms.ToTensor()]), \n",
    "        )\n",
    "    val_ratio = 0.01\n",
    "    val_split = int(val_ratio*len(test_ds))\n",
    "    val_data, test_data = random_split(\n",
    "        test_ds, [val_split, len(test_ds)-val_split]\n",
    "    )\n",
    "    \n",
    "    train_net(net, train_data, pretrain_ds, val_data, dev=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = \"model.pth\"\n",
    "model = torch.load(FILE)\n",
    "model.eval()\n",
    "\n",
    "image_lst = [0]*10\n",
    "right_pred = 0\n",
    "for i in range(len(test_data)):\n",
    "    if max_index(model.forward(test_data[i][0]))==test_data[i][1]:\n",
    "        right_pred+=1\n",
    "    image_lst[max_index(model.forward(test_data[i][0]))]+=1\n",
    "    \n",
    "print(\"model's accuracy:\",right_pred/100,\"%\")\n",
    "print(image_lst)\n",
    "plt.plot(plot_lst)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
