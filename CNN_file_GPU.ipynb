{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim, autograd as grad\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets \n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from AddFunc import ret_shape,max_index,val_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code classifies 10 different classes of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.convL1 = nn.Conv2d(in_channels=3,out_channels=64, \n",
    "                                kernel_size=(3,3), stride= (1,1),padding=2)\n",
    "        nn.init.kaiming_normal(self.convL1.weight)\n",
    "        self.convL2 = nn.Conv2d(in_channels=64,out_channels=48, \n",
    "                                kernel_size=(3,3), stride= (1,1),padding=2)\n",
    "        nn.init.kaiming_normal(self.convL2.weight)\n",
    "        self.convL3 = nn.Conv2d(in_channels=48,out_channels=32, \n",
    "                                kernel_size=(2,2), stride= (1,1),padding=1)\n",
    "        nn.init.kaiming_normal(self.convL1.weight)\n",
    "\n",
    "\n",
    "        self.linL4 = nn.Linear(1568, 10, bias=True)\n",
    "        nn.init.xavier_uniform_(self.linL4.weight)\n",
    "        self.pool3 = nn.MaxPool2d((3,3), (3,3))\n",
    "        self.pool2 = nn.MaxPool2d((2,2), (2,2))\n",
    "\n",
    "\n",
    "        self.relu = nn.ReLU()  \n",
    "        self.Batch_norm = nn.BatchNorm1d(num_features=32)\n",
    "        self.Lrelu = nn.LeakyReLU()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.Softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.Batch_norm(x)\n",
    "        x=self.Lrelu(self.convL1(x))\n",
    "        x=self.pool3(x)\n",
    "        x=self.relu(self.convL2(x))\n",
    "        x=self.pool2(x)\n",
    "        x=self.relu(self.convL3(x))\n",
    "\n",
    "        x=torch.flatten(x)\n",
    "        x=self.Softmax(self.linL4(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.data[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single epoch training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_one_epoch(cnn, FILE_PATH, train_ds, optimizer, dev, epoch_iter, tr_error):\n",
    "    iter = 0\n",
    "    tr_error.append(0)\n",
    "    \n",
    "    # Training loop part\n",
    "    for sample in train_ds:\n",
    "        cnn = cnn.to(dev) # Added due to errors (Should remain in the loop)\n",
    "        targetY = torch.nn.functional.one_hot(\n",
    "            torch.tensor(sample[1]), num_classes=10)\n",
    "        targetY = torch.tensor(targetY, dtype=torch.float32, requires_grad=True)\n",
    "        targetY = torch.squeeze(targetY).to(dev)\n",
    "        \n",
    "        pred = cnn.forward(torch.squeeze(sample[0]).to(dev))\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        # ---BackPropagation---\n",
    "        loss = loss_func(pred, targetY)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if iter%100==0:\n",
    "            torch.save(cnn.cpu(), FILE_PATH)\n",
    "            grad_tmp = cnn.linL4.weight.grad\n",
    "            tr_error[epoch_iter]+=loss\n",
    "            print(iter,\"({})\".format(epoch_iter+1), \" | \",abs(grad_tmp.sum())/len(grad_tmp))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        iter+=1\n",
    "    \n",
    "    tr_error[epoch_iter] /= iter # To calculate a mean error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = \"model.pth\"\n",
    "tr_error = [] #The total error of the train time at a single epoch\n",
    "\n",
    "def train_net(cnn, train_ds, val_ds, dev,test_data):\n",
    "    iter = 0\n",
    "    epoch_num = 7 # Determines the epoch number\n",
    "\n",
    "    # Pre-train and validation phase\n",
    "    #valtr_num = 2000 # The scale of the minibatch used to train the CNNs that are to be validated\n",
    "    #val_train, reg_train = random_split(train_ds, [valtr_num, len(train_ds)-valtr_num])\n",
    "\n",
    "    # Multiple epoch training phase\n",
    "    optimizer = optim.SGD(params=cnn.parameters(), lr=6.25e-4,\n",
    "                          momentum=0.9,\n",
    "                          weight_decay=2e-5)\n",
    "    #optimizer = optim.Adam(params=cnn.parameters(),lr=5e-4, betas=[0.99,0.999])\n",
    "    test_epoch_loss = 0\n",
    "    for i in range(epoch_num):\n",
    "        test_epoch_loss = 0\n",
    "        train_one_epoch(cnn, FILE_PATH, train_ds, optimizer, dev,epoch_iter=i, tr_error=tr_error)\n",
    "        for i in range(len(test_data)):\n",
    "            test_epoch_loss+=\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # Accessing processing unit\n",
    "    if torch.cuda.is_available() : device = \"cuda:0\"\n",
    "    else : device = \"cpu\"\n",
    "    device = torch.device(device)\n",
    "    net = CNN().to(device)\n",
    "\n",
    "    # Loading the datasets\n",
    "    train_data = torchvision.datasets.CIFAR10(\n",
    "        root= \"C:/Users/orian/OneDrive/שולחן העבודה/My Coding Files\"\n",
    "        ,train=True, transform=transforms.Compose([transforms.ToTensor()])\n",
    "        #, target_transform=transforms.Compose([transforms.ToTensor()])\n",
    "    )\n",
    "    train_data = DataLoader(train_data, shuffle=True, num_workers=3)\n",
    "\n",
    "    test_data = torchvision.datasets.CIFAR10(\n",
    "        root= \"C:/Users/orian/OneDrive/שולחן העבודה/My Coding Files\"\n",
    "        ,train=False, transform=transforms.Compose([transforms.ToTensor()]), \n",
    "    )\n",
    "    val_data, test_data = random_split(test_data, [1000, len(test_data)-1000])\n",
    "\n",
    "    \n",
    "    train_net(net, train_data, val_data,dev=device,test_data=test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = \"model.pth\"\n",
    "model = torch.load(FILE)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "image_lst = [0]*10\n",
    "right_pred = 0\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    if max_index(model.forward(test_data[i][0]))==test_data[i][1]:\n",
    "        right_pred+=1\n",
    "    image_lst[max_index(model.forward(test_data[i][0]))]+=1\n",
    "print(\"model's accuracy:\",right_pred/100,\"%\")\n",
    "print(image_lst)\n",
    "\n",
    "tr_err_arr = [j.detach().cpu().numpy() for j in tr_error] # Converts the cuda tensor to numpy\n",
    "plt.plot(tr_err_arr) \n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
