{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim, autograd as grad\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code classifies 10 different classes of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.convL1 = nn.Conv2d(in_channels=3,out_channels=128, \n",
    "                                kernel_size=(3,3), stride= (1,1),padding=2)\n",
    "        nn.init.kaiming_normal(self.convL1.weight)\n",
    "        self.convL2 = nn.Conv2d(in_channels=128,out_channels=64, \n",
    "                                kernel_size=(3,3), stride= (1,1),padding=2)\n",
    "        nn.init.kaiming_normal(self.convL2.weight)\n",
    "        self.convL3 = nn.Conv2d(in_channels=64,out_channels=32, \n",
    "                                kernel_size=(2,2), stride= (1,1),padding=2)\n",
    "        nn.init.kaiming_normal(self.convL1.weight)\n",
    "\n",
    "\n",
    "        self.linL4 = nn.Linear(2592, 1000, bias=True)\n",
    "        self.linL5 = nn.Linear(1000, 10, bias=True)\n",
    "        nn.init.kaiming_uniform_(self.linL4.weight)\n",
    "        nn.init.kaiming_uniform_(self.linL5.weight)\n",
    "        self.pool3 = nn.MaxPool2d((3,3), (3,3))\n",
    "        self.pool2 = nn.MaxPool2d((2,2), (2,2))\n",
    "\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.relu = nn.ReLU()  \n",
    "        self.Batch_norm = nn.BatchNorm1d(num_features=32)\n",
    "        self.Lrelu = nn.LeakyReLU()\n",
    "        self.Softplus = nn.Softplus()\n",
    "        self.Softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.Batch_norm(x)\n",
    "        x=self.Lrelu(self.convL1(x))\n",
    "        x=self.pool3(x)\n",
    "        x=self.relu(self.convL2(x))\n",
    "        x=self.pool2(x)\n",
    "        x=self.relu(self.convL3(x))\n",
    "\n",
    "        x=torch.flatten(x)\n",
    "        x=self.Lrelu(self.linL4(x))\n",
    "        x=self.dropout(x)\n",
    "        x=self.Softmax(self.linL5(x))\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.data[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_shape(training_set)->str:\n",
    "    ret_string = \"\"\n",
    "    for idx, data in enumerate(training_set):\n",
    "            datas = data[0]\n",
    "            labels = data[1]\n",
    "            ret_string+=\"{}\\n\".format(datas.shape)\n",
    "            ret_string+=\"Labels:{}\\n\".format(labels)\n",
    "            ret_string+=\"Labels shape:{}\\n\".format(len(labels))\n",
    "            ret_string+=\"Labels[0] shape:{}\\n\".format(labels[0].shape)\n",
    "            break\n",
    "    return ret_string\n",
    "\n",
    "\n",
    "def max_index(max_tnsr):\n",
    "    max_tnsr = torch.tensor(max_tnsr)\n",
    "    max_tnsr = max_tnsr.tolist()\n",
    "    max_num = 0\n",
    "    for num in max_tnsr:\n",
    "        if max_num < num:\n",
    "            max_num = num\n",
    "    return max_tnsr.index(max_num)\n",
    "\n",
    "\n",
    "def val_func(convNet, cnn_num,valDS, x_val, y_val):\n",
    "    right_val = [0]*cnn_num # represents the 10 cnns\n",
    "    print(\"\\n| Starting validation set run |\\n\")\n",
    "    for val_sample in valDS:\n",
    "        for j in range(cnn_num):\n",
    "            prediction = convNet[j].forward(torch.squeeze(x_val))\n",
    "            if max_index(prediction) == y_val:\n",
    "                right_val[j]+=1\n",
    "                convNet = convNet[max_index(right_val)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = \"model.pth\"\n",
    "plot_lst = []\n",
    "cnn_num = 10\n",
    "\n",
    "\n",
    "def train_net(cnn, train_ds, val_ds, dev):\n",
    "    iter = 0\n",
    "    lrs = [num / int(1e4) for num in range(1, 10)]# The learning rates of\n",
    "                                                #the 10 different CNNs\n",
    "    momentums = [num / 10 for num in range(1,10)]\n",
    "    momentums = momentums[4:] + momentums[:4]# Shift from the middle\n",
    "\n",
    "    #optimizer = optim.Adam(params=cnn.parameters(), weight_decay=0.01\n",
    "    #                    , lr=1e-4, betas=[0.6, 0.6])\n",
    "\n",
    "    # Training loop part\n",
    "    for sample in train_ds:\n",
    "        for i in range(len(cnn)):\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\orian\\AppData\\Local\\Temp\\ipykernel_34080\\3604079781.py:6: FutureWarning: `nn.init.kaiming_normal` is now deprecated in favor of `nn.init.kaiming_normal_`.\n",
      "  nn.init.kaiming_normal(self.convL1.weight)\n",
      "C:\\Users\\orian\\AppData\\Local\\Temp\\ipykernel_34080\\3604079781.py:9: FutureWarning: `nn.init.kaiming_normal` is now deprecated in favor of `nn.init.kaiming_normal_`.\n",
      "  nn.init.kaiming_normal(self.convL2.weight)\n",
      "C:\\Users\\orian\\AppData\\Local\\Temp\\ipykernel_34080\\3604079781.py:12: FutureWarning: `nn.init.kaiming_normal` is now deprecated in favor of `nn.init.kaiming_normal_`.\n",
      "  nn.init.kaiming_normal(self.convL1.weight)\n",
      "C:\\Users\\orian\\AppData\\Local\\Temp\\ipykernel_34080\\4244664313.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(sample[1]), num_classes=10)\n",
      "C:\\Users\\orian\\AppData\\Local\\Temp\\ipykernel_34080\\4244664313.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targetY = torch.tensor(targetY, dtype=torch.float32, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  |  tensor(-3.4571e-07)\n",
      "100  |  tensor(1.9670e-07)\n",
      "200  |  tensor(2.0117e-08)\n",
      "300  |  tensor(3.0249e-07)\n",
      "400  |  tensor(5.9046e-08)\n",
      "500  |  tensor(-1.4305e-07)\n",
      "600  |  tensor(3.1143e-07)\n",
      "700  |  tensor(2.7120e-07)\n",
      "800  |  tensor(1.6717e-08)\n",
      "900  |  tensor(1.8394e-07)\n",
      "1000  |  tensor(5.7518e-07)\n",
      "1100  |  tensor(-1.4976e-07)\n",
      "1200  |  tensor(-6.8918e-08)\n",
      "1300  |  tensor(-1.1101e-07)\n",
      "1400  |  tensor(-1.0147e-07)\n",
      "1500  |  tensor(-1.5944e-07)\n",
      "\n",
      "| Starting validation set run |\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\orian\\AppData\\Local\\Temp\\ipykernel_34080\\2157939635.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_tnsr = torch.tensor(max_tnsr)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 32\u001b[0m\n\u001b[0;32m     28\u001b[0m test_data, val_data \u001b[38;5;241m=\u001b[39m random_split(\n\u001b[0;32m     29\u001b[0m     test_ds, [val_split, \u001b[38;5;28mlen\u001b[39m(test_ds)\u001b[38;5;241m-\u001b[39mval_split])\n\u001b[0;32m     31\u001b[0m train_data \u001b[38;5;241m=\u001b[39m DataLoader(train_data, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 32\u001b[0m \u001b[43mtrain_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[54], line 18\u001b[0m, in \u001b[0;36mtrain_net\u001b[1;34m(cnn, train_ds, val_ds, dev)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m train_ds:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(cnn)):\n\u001b[1;32m---> 18\u001b[0m         optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(params\u001b[38;5;241m=\u001b[39m\u001b[43mcnn\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m,\n\u001b[0;32m     19\u001b[0m                         momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.699\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[0;32m     21\u001b[0m         targetY \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mone_hot(\n\u001b[0;32m     22\u001b[0m             torch\u001b[38;5;241m.\u001b[39mtensor(sample[\u001b[38;5;241m1\u001b[39m]), num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     23\u001b[0m         targetY \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(targetY, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # Accessing processing unit\n",
    "    if torch.cuda.is_available() : device = \"cuda:0\"\n",
    "    else : device = \"cpu\"\n",
    "    device = torch.device(device)\n",
    "    net = [0]*10\n",
    "    for i in range(len(net)):                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "        net[i]=CNN().to(device)\n",
    "\n",
    "    # Loading the dataset\n",
    "    #for i in range(2):\n",
    "    train_data = torchvision.datasets.CIFAR10(\n",
    "        root= \"C:/Users/orian/OneDrive/שולחן העבודה/My Coding Files\"\n",
    "        ,train=True, transform=transforms.Compose([transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                    ])\n",
    "        #, target_transform=transforms.Compose([transforms.ToTensor()])\n",
    "    )\n",
    "\n",
    "    \n",
    "    test_ds = torchvision.datasets.CIFAR10(\n",
    "            root= \"C:/Users/orian/OneDrive/שולחן העבודה/My Coding Files\"\n",
    "            ,train=False, transform=transforms.Compose([transforms.ToTensor()]), \n",
    "        )\n",
    "    val_ratio = 0.1\n",
    "    val_split = int(val_ratio*len(test_ds))\n",
    "    test_data, val_data = random_split(\n",
    "        test_ds, [val_split, len(test_ds)-val_split])\n",
    "        \n",
    "    train_data = DataLoader(train_data, shuffle=True)\n",
    "    train_net(net, train_data, val_data, dev=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = \"model.pth\"\n",
    "model = torch.load(FILE)\n",
    "model.eval()\n",
    "\n",
    "image_lst = [0]*10\n",
    "right_pred = 0\n",
    "for i in range(len(test_data)):\n",
    "    if max_index(model.forward(test_data[i][0]))==test_data[i][1]:\n",
    "        right_pred+=1\n",
    "    image_lst[max_index(model.forward(test_data[i][0]))]+=1\n",
    "    \n",
    "print(\"model's accuracy:\",right_pred/100,\"%\")\n",
    "print(image_lst)\n",
    "plt.plot(plot_lst)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
